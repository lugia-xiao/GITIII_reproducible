{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c2ae13-2c7d-41be-80da-0ce2ba39ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have samples: ['mouse1_slice201']\n",
      "There are totally 6137 cells in this dataset\n",
      "500 / 6137\n",
      "1000 / 6137\n",
      "1500 / 6137\n",
      "2000 / 6137\n",
      "2500 / 6137\n",
      "3000 / 6137\n",
      "3500 / 6137\n",
      "4000 / 6137\n",
      "4500 / 6137\n",
      "5000 / 6137\n",
      "5500 / 6137\n",
      "6000 / 6137\n",
      "Finish mouse1_slice201\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from model import GITIII,Loss_function\n",
    "from calculate_PCC import Calculate_PCC\n",
    "\n",
    "from dataloader import Mouse_brain_evaluate_dataset\n",
    "\n",
    "to_save_dir=\"../edges/\"\n",
    "data_dir=\"../../data/Mouse_brain/processed1/\"\n",
    "\n",
    "ligands_info = torch.load(\"/\".join(data_dir.split(\"/\")[:-2]) + \"/ligands.pth\")\n",
    "genes = torch.load(\"/\".join(data_dir.split(\"/\")[:-2]) + \"/genes.pth\")\n",
    "\n",
    "my_model = GITIII(genes, ligands_info, node_dim=256, edge_dim=48, num_heads=2,n_layers=1, node_dim_small=16,att_dim=8)\n",
    "my_model = my_model.cuda()\n",
    "\n",
    "my_model.load_state_dict(torch.load(\"GRIT_best.pth\"))\n",
    "\n",
    "loss_func = Loss_function(genes, ligands_info).cuda()\n",
    "evaluator=Calculate_PCC(genes,ligands_info)\n",
    "\n",
    "cell_types_dict = {}\n",
    "cnt = 0\n",
    "for cell_typei in ['Astro', 'Endo', 'L2/3 IT', 'L4/5 IT', 'L5 ET', 'L5 IT', 'L5/6 NP', 'L6 CT', 'L6 IT',\n",
    "                      'L6 IT Car3', 'L6b', 'Lamp5', 'Micro', 'OPC', 'Oligo', 'PVM', 'Peri', 'Pvalb', 'SMC', 'Sncg',\n",
    "                      'Sst', 'VLMC', 'Vip', 'other']:\n",
    "    cell_types_dict[cnt] = cell_typei\n",
    "    cnt += 1\n",
    "\n",
    "def evaluate_Brain_MERFISH(sample):\n",
    "    my_dataset = dataset = Mouse_brain_evaluate_dataset(processed_dir=data_dir, sample=sample)\n",
    "    my_dataloader = DataLoader(my_dataset, batch_size=1, num_workers=0,shuffle=False)\n",
    "\n",
    "    length=len(my_dataloader)\n",
    "\n",
    "    my_model.eval()\n",
    "\n",
    "    results=[]\n",
    "    with torch.no_grad():\n",
    "        for (stepi, x) in enumerate(my_dataloader, start=1):\n",
    "            x = {k: v.cuda() for k, v in x.items()}\n",
    "\n",
    "            cell_type_name=[cell_types_dict[int(i.cpu())] for i in x[\"cell_types\"].squeeze(dim=0)]\n",
    "\n",
    "            y_pred = my_model(x)\n",
    "            y = x[\"y\"]\n",
    "            lossi1, lossi2 = loss_func(y_pred, y)\n",
    "            lossi1=lossi1.cpu().detach()\n",
    "            lossi2=lossi2.cpu().detach()\n",
    "\n",
    "            attention_score = y_pred[1][0].cpu().detach()\n",
    "            attention_score = attention_score.squeeze(dim=0)\n",
    "            attention_score=attention_score.permute(1,2,0)[0,:,:]\n",
    "            #print(torch.topk(attention_score[0, :], k=30, dim=-1))\n",
    "\n",
    "            edges = y_pred[1][1].cpu().detach()\n",
    "            edges = edges.squeeze(dim=0).permute(1,2,0)[0,:,:]\n",
    "\n",
    "            position_x = x[\"position_x\"].cpu().detach().squeeze(dim=0)\n",
    "            position_y = x[\"position_y\"].cpu().detach().squeeze(dim=0)\n",
    "\n",
    "            to_save_dict = {\n",
    "                \"edges\": edges,\n",
    "                \"attention_score\": attention_score,\n",
    "                \"position_x\": position_x,\n",
    "                \"position_y\": position_y,\n",
    "                \"cell_type_name\": cell_type_name,\n",
    "                \"loss_all\": lossi1,\n",
    "                \"loss_no_interact\": lossi2,\n",
    "                \"y_pred\": y_pred[0].cpu().detach().squeeze(dim=0),\n",
    "                \"y\": y.cpu().detach().squeeze(dim=0)\n",
    "            }\n",
    "            results.append(to_save_dict)\n",
    "\n",
    "            if stepi%500==0:\n",
    "                print(stepi,\"/\",length)\n",
    "    concatenated_results={}\n",
    "    for keyi in results[0].keys():\n",
    "        if keyi not in [\"cell_type_name\"]:\n",
    "            concatenated_results[keyi]=torch.stack([results[j][keyi] for j in range(len(results))],dim=0)\n",
    "        else:\n",
    "            concatenated_results[keyi]=[results[j][keyi] for j in range(len(results))]\n",
    "    torch.save(concatenated_results,to_save_dir+\"edges_\"+sample+\".pth\")\n",
    "    \n",
    "    print(\"Finish\", sample)\n",
    "    return concatenated_results\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    mouse1_slice201=evaluate_Brain_MERFISH('mouse1_slice201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875f4d5a-92be-4ad6-a297-d4efe05cbf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges torch.Size([6137, 99, 48])\n",
      "attention_score torch.Size([6137, 99, 254])\n",
      "position_x torch.Size([6137, 100])\n",
      "position_y torch.Size([6137, 100])\n",
      "cell_type_name 6137 100\n",
      "loss_all torch.Size([6137])\n",
      "loss_no_interact torch.Size([6137])\n",
      "y_pred torch.Size([6137, 254])\n",
      "y torch.Size([6137, 254])\n"
     ]
    }
   ],
   "source": [
    "for keyi in mouse1_slice201.keys():\n",
    "    if keyi not in [\"cell_type_name\"]:\n",
    "        print(keyi,mouse1_slice201[keyi].shape)\n",
    "    else:\n",
    "        print(keyi,len(mouse1_slice201[keyi]),len(mouse1_slice201[keyi][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66456be1-679c-4e9c-b68e-d68b9fa44e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have samples: ['mouse1_slice1']\n",
      "There are totally 2345 cells in this dataset\n",
      "500 / 2345\n",
      "1000 / 2345\n",
      "1500 / 2345\n",
      "2000 / 2345\n",
      "Finish mouse1_slice1\n",
      "Have samples: ['mouse1_slice10']\n",
      "There are totally 2391 cells in this dataset\n",
      "500 / 2391\n",
      "1000 / 2391\n",
      "1500 / 2391\n",
      "2000 / 2391\n",
      "Finish mouse1_slice10\n",
      "Have samples: ['mouse1_slice102']\n",
      "There are totally 6630 cells in this dataset\n",
      "500 / 6630\n",
      "1000 / 6630\n",
      "1500 / 6630\n",
      "2000 / 6630\n",
      "2500 / 6630\n",
      "3000 / 6630\n",
      "3500 / 6630\n",
      "4000 / 6630\n",
      "4500 / 6630\n",
      "5000 / 6630\n",
      "5500 / 6630\n",
      "6000 / 6630\n",
      "6500 / 6630\n",
      "Finish mouse1_slice102\n",
      "Have samples: ['mouse1_slice112']\n",
      "There are totally 4920 cells in this dataset\n",
      "500 / 4920\n",
      "1000 / 4920\n",
      "1500 / 4920\n",
      "2000 / 4920\n",
      "2500 / 4920\n",
      "3000 / 4920\n",
      "3500 / 4920\n",
      "4000 / 4920\n",
      "4500 / 4920\n",
      "Finish mouse1_slice112\n",
      "Have samples: ['mouse1_slice122']\n",
      "There are totally 6082 cells in this dataset\n",
      "500 / 6082\n",
      "1000 / 6082\n",
      "1500 / 6082\n",
      "2000 / 6082\n",
      "2500 / 6082\n",
      "3000 / 6082\n",
      "3500 / 6082\n",
      "4000 / 6082\n",
      "4500 / 6082\n",
      "5000 / 6082\n",
      "5500 / 6082\n",
      "6000 / 6082\n",
      "Finish mouse1_slice122\n",
      "Have samples: ['mouse1_slice131']\n",
      "There are totally 4992 cells in this dataset\n",
      "500 / 4992\n",
      "1000 / 4992\n",
      "1500 / 4992\n",
      "2000 / 4992\n",
      "2500 / 4992\n",
      "3000 / 4992\n",
      "3500 / 4992\n",
      "4000 / 4992\n",
      "4500 / 4992\n",
      "Finish mouse1_slice131\n",
      "Have samples: ['mouse1_slice153']\n",
      "There are totally 7517 cells in this dataset\n",
      "500 / 7517\n",
      "1000 / 7517\n",
      "1500 / 7517\n",
      "2000 / 7517\n",
      "2500 / 7517\n",
      "3000 / 7517\n",
      "3500 / 7517\n",
      "4000 / 7517\n",
      "4500 / 7517\n",
      "5000 / 7517\n",
      "5500 / 7517\n",
      "6000 / 7517\n",
      "6500 / 7517\n",
      "7000 / 7517\n",
      "7500 / 7517\n",
      "Finish mouse1_slice153\n",
      "Have samples: ['mouse1_slice162']\n",
      "There are totally 6863 cells in this dataset\n",
      "500 / 6863\n",
      "1000 / 6863\n",
      "1500 / 6863\n",
      "2000 / 6863\n",
      "2500 / 6863\n",
      "3000 / 6863\n",
      "3500 / 6863\n",
      "4000 / 6863\n",
      "4500 / 6863\n",
      "5000 / 6863\n",
      "5500 / 6863\n",
      "6000 / 6863\n",
      "6500 / 6863\n",
      "Finish mouse1_slice162\n",
      "Have samples: ['mouse1_slice170']\n",
      "There are totally 6353 cells in this dataset\n",
      "500 / 6353\n",
      "1000 / 6353\n",
      "1500 / 6353\n",
      "2000 / 6353\n",
      "2500 / 6353\n",
      "3000 / 6353\n",
      "3500 / 6353\n",
      "4000 / 6353\n",
      "4500 / 6353\n",
      "5000 / 6353\n",
      "5500 / 6353\n",
      "6000 / 6353\n",
      "Finish mouse1_slice170\n",
      "Have samples: ['mouse1_slice180']\n",
      "There are totally 6172 cells in this dataset\n",
      "500 / 6172\n",
      "1000 / 6172\n",
      "1500 / 6172\n",
      "2000 / 6172\n",
      "2500 / 6172\n",
      "3000 / 6172\n",
      "3500 / 6172\n",
      "4000 / 6172\n",
      "4500 / 6172\n",
      "5000 / 6172\n",
      "5500 / 6172\n",
      "6000 / 6172\n",
      "Finish mouse1_slice180\n",
      "Have samples: ['mouse1_slice190']\n",
      "There are totally 5636 cells in this dataset\n",
      "500 / 5636\n",
      "1000 / 5636\n",
      "1500 / 5636\n",
      "2000 / 5636\n",
      "2500 / 5636\n",
      "3000 / 5636\n",
      "3500 / 5636\n",
      "4000 / 5636\n",
      "4500 / 5636\n",
      "5000 / 5636\n",
      "5500 / 5636\n",
      "Finish mouse1_slice190\n",
      "Have samples: ['mouse1_slice200']\n",
      "There are totally 2168 cells in this dataset\n",
      "500 / 2168\n",
      "1000 / 2168\n",
      "1500 / 2168\n",
      "2000 / 2168\n",
      "Finish mouse1_slice200\n",
      "Have samples: ['mouse1_slice201']\n",
      "There are totally 6137 cells in this dataset\n",
      "500 / 6137\n",
      "1000 / 6137\n",
      "1500 / 6137\n",
      "2000 / 6137\n",
      "2500 / 6137\n",
      "3000 / 6137\n",
      "3500 / 6137\n",
      "4000 / 6137\n",
      "4500 / 6137\n",
      "5000 / 6137\n",
      "5500 / 6137\n",
      "6000 / 6137\n",
      "Finish mouse1_slice201\n",
      "Have samples: ['mouse1_slice21']\n",
      "There are totally 2010 cells in this dataset\n",
      "500 / 2010\n",
      "1000 / 2010\n",
      "1500 / 2010\n",
      "2000 / 2010\n",
      "Finish mouse1_slice21\n",
      "Have samples: ['mouse1_slice212']\n",
      "There are totally 6445 cells in this dataset\n",
      "500 / 6445\n",
      "1000 / 6445\n",
      "1500 / 6445\n",
      "2000 / 6445\n",
      "2500 / 6445\n",
      "3000 / 6445\n",
      "3500 / 6445\n",
      "4000 / 6445\n",
      "4500 / 6445\n",
      "5000 / 6445\n",
      "5500 / 6445\n",
      "6000 / 6445\n",
      "Finish mouse1_slice212\n",
      "Have samples: ['mouse1_slice221']\n",
      "There are totally 5696 cells in this dataset\n",
      "500 / 5696\n",
      "1000 / 5696\n",
      "1500 / 5696\n",
      "2000 / 5696\n",
      "2500 / 5696\n",
      "3000 / 5696\n",
      "3500 / 5696\n",
      "4000 / 5696\n",
      "4500 / 5696\n",
      "5000 / 5696\n",
      "5500 / 5696\n",
      "Finish mouse1_slice221\n",
      "Have samples: ['mouse1_slice232']\n",
      "There are totally 5286 cells in this dataset\n",
      "500 / 5286\n",
      "1000 / 5286\n",
      "1500 / 5286\n",
      "2000 / 5286\n",
      "2500 / 5286\n",
      "3000 / 5286\n",
      "3500 / 5286\n",
      "4000 / 5286\n",
      "4500 / 5286\n",
      "5000 / 5286\n",
      "Finish mouse1_slice232\n",
      "Have samples: ['mouse1_slice241']\n",
      "There are totally 3990 cells in this dataset\n",
      "500 / 3990\n",
      "1000 / 3990\n",
      "1500 / 3990\n",
      "2000 / 3990\n",
      "2500 / 3990\n",
      "3000 / 3990\n",
      "3500 / 3990\n",
      "Finish mouse1_slice241\n",
      "Have samples: ['mouse1_slice251']\n",
      "There are totally 4366 cells in this dataset\n",
      "500 / 4366\n",
      "1000 / 4366\n",
      "1500 / 4366\n",
      "2000 / 4366\n",
      "2500 / 4366\n",
      "3000 / 4366\n",
      "3500 / 4366\n",
      "4000 / 4366\n",
      "Finish mouse1_slice251\n",
      "Have samples: ['mouse1_slice260']\n",
      "There are totally 5656 cells in this dataset\n",
      "500 / 5656\n",
      "1000 / 5656\n",
      "1500 / 5656\n",
      "2000 / 5656\n",
      "2500 / 5656\n",
      "3000 / 5656\n",
      "3500 / 5656\n",
      "4000 / 5656\n",
      "4500 / 5656\n",
      "5000 / 5656\n",
      "5500 / 5656\n",
      "Finish mouse1_slice260\n",
      "Have samples: ['mouse1_slice271']\n",
      "There are totally 3854 cells in this dataset\n",
      "500 / 3854\n",
      "1000 / 3854\n",
      "1500 / 3854\n",
      "2000 / 3854\n",
      "2500 / 3854\n",
      "3000 / 3854\n",
      "3500 / 3854\n",
      "Finish mouse1_slice271\n",
      "Have samples: ['mouse1_slice283']\n",
      "There are totally 4251 cells in this dataset\n",
      "500 / 4251\n",
      "1000 / 4251\n",
      "1500 / 4251\n",
      "2000 / 4251\n",
      "2500 / 4251\n",
      "3000 / 4251\n",
      "3500 / 4251\n",
      "4000 / 4251\n",
      "Finish mouse1_slice283\n",
      "Have samples: ['mouse1_slice291']\n",
      "There are totally 4391 cells in this dataset\n",
      "500 / 4391\n",
      "1000 / 4391\n",
      "1500 / 4391\n",
      "2000 / 4391\n",
      "2500 / 4391\n",
      "3000 / 4391\n",
      "3500 / 4391\n",
      "4000 / 4391\n",
      "Finish mouse1_slice291\n",
      "Have samples: ['mouse1_slice301']\n",
      "There are totally 4343 cells in this dataset\n",
      "500 / 4343\n",
      "1000 / 4343\n",
      "1500 / 4343\n",
      "2000 / 4343\n",
      "2500 / 4343\n",
      "3000 / 4343\n",
      "3500 / 4343\n",
      "4000 / 4343\n",
      "Finish mouse1_slice301\n",
      "Have samples: ['mouse1_slice31']\n",
      "There are totally 3063 cells in this dataset\n",
      "500 / 3063\n",
      "1000 / 3063\n",
      "1500 / 3063\n",
      "2000 / 3063\n",
      "2500 / 3063\n",
      "3000 / 3063\n",
      "Finish mouse1_slice31\n",
      "Have samples: ['mouse1_slice313']\n",
      "There are totally 3847 cells in this dataset\n",
      "500 / 3847\n",
      "1000 / 3847\n",
      "1500 / 3847\n",
      "2000 / 3847\n",
      "2500 / 3847\n",
      "3000 / 3847\n",
      "3500 / 3847\n",
      "Finish mouse1_slice313\n",
      "Have samples: ['mouse1_slice326']\n",
      "There are totally 4101 cells in this dataset\n",
      "500 / 4101\n",
      "1000 / 4101\n",
      "1500 / 4101\n",
      "2000 / 4101\n",
      "2500 / 4101\n",
      "3000 / 4101\n",
      "3500 / 4101\n",
      "4000 / 4101\n",
      "Finish mouse1_slice326\n",
      "Have samples: ['mouse1_slice40']\n",
      "There are totally 4096 cells in this dataset\n",
      "500 / 4096\n",
      "1000 / 4096\n",
      "1500 / 4096\n",
      "2000 / 4096\n",
      "2500 / 4096\n",
      "3000 / 4096\n",
      "3500 / 4096\n",
      "4000 / 4096\n",
      "Finish mouse1_slice40\n",
      "Have samples: ['mouse1_slice50']\n",
      "There are totally 4282 cells in this dataset\n",
      "500 / 4282\n",
      "1000 / 4282\n",
      "1500 / 4282\n",
      "2000 / 4282\n",
      "2500 / 4282\n",
      "3000 / 4282\n",
      "3500 / 4282\n",
      "4000 / 4282\n",
      "Finish mouse1_slice50\n",
      "Have samples: ['mouse1_slice62']\n",
      "There are totally 4716 cells in this dataset\n",
      "500 / 4716\n",
      "1000 / 4716\n",
      "1500 / 4716\n",
      "2000 / 4716\n",
      "2500 / 4716\n",
      "3000 / 4716\n",
      "3500 / 4716\n",
      "4000 / 4716\n",
      "4500 / 4716\n",
      "Finish mouse1_slice62\n",
      "Have samples: ['mouse1_slice71']\n",
      "There are totally 5663 cells in this dataset\n",
      "500 / 5663\n",
      "1000 / 5663\n",
      "1500 / 5663\n",
      "2000 / 5663\n",
      "2500 / 5663\n",
      "3000 / 5663\n",
      "3500 / 5663\n",
      "4000 / 5663\n",
      "4500 / 5663\n",
      "5000 / 5663\n",
      "5500 / 5663\n",
      "Finish mouse1_slice71\n",
      "Have samples: ['mouse1_slice81']\n",
      "There are totally 5179 cells in this dataset\n",
      "500 / 5179\n",
      "1000 / 5179\n",
      "1500 / 5179\n",
      "2000 / 5179\n",
      "2500 / 5179\n",
      "3000 / 5179\n",
      "3500 / 5179\n",
      "4000 / 5179\n",
      "4500 / 5179\n",
      "5000 / 5179\n",
      "Finish mouse1_slice81\n",
      "Have samples: ['mouse1_slice91']\n",
      "There are totally 5571 cells in this dataset\n",
      "500 / 5571\n",
      "1000 / 5571\n",
      "1500 / 5571\n",
      "2000 / 5571\n",
      "2500 / 5571\n",
      "3000 / 5571\n",
      "3500 / 5571\n",
      "4000 / 5571\n",
      "4500 / 5571\n",
      "5000 / 5571\n",
      "5500 / 5571\n",
      "Finish mouse1_slice91\n",
      "Have samples: ['mouse2_slice1']\n",
      "There are totally 1684 cells in this dataset\n",
      "500 / 1684\n",
      "1000 / 1684\n",
      "1500 / 1684\n",
      "Finish mouse2_slice1\n",
      "Have samples: ['mouse2_slice10']\n",
      "There are totally 1144 cells in this dataset\n",
      "500 / 1144\n",
      "1000 / 1144\n",
      "Finish mouse2_slice10\n",
      "Have samples: ['mouse2_slice109']\n",
      "There are totally 5135 cells in this dataset\n",
      "500 / 5135\n",
      "1000 / 5135\n",
      "1500 / 5135\n",
      "2000 / 5135\n",
      "2500 / 5135\n",
      "3000 / 5135\n",
      "3500 / 5135\n",
      "4000 / 5135\n",
      "4500 / 5135\n",
      "5000 / 5135\n",
      "Finish mouse2_slice109\n",
      "Have samples: ['mouse2_slice119']\n",
      "There are totally 4968 cells in this dataset\n",
      "500 / 4968\n",
      "1000 / 4968\n",
      "1500 / 4968\n",
      "2000 / 4968\n",
      "2500 / 4968\n",
      "3000 / 4968\n",
      "3500 / 4968\n",
      "4000 / 4968\n",
      "4500 / 4968\n",
      "Finish mouse2_slice119\n",
      "Have samples: ['mouse2_slice129']\n",
      "There are totally 5089 cells in this dataset\n",
      "500 / 5089\n",
      "1000 / 5089\n",
      "1500 / 5089\n",
      "2000 / 5089\n",
      "2500 / 5089\n",
      "3000 / 5089\n",
      "3500 / 5089\n",
      "4000 / 5089\n",
      "4500 / 5089\n",
      "5000 / 5089\n",
      "Finish mouse2_slice129\n",
      "Have samples: ['mouse2_slice139']\n",
      "There are totally 4153 cells in this dataset\n",
      "500 / 4153\n",
      "1000 / 4153\n",
      "1500 / 4153\n",
      "2000 / 4153\n",
      "2500 / 4153\n",
      "3000 / 4153\n",
      "3500 / 4153\n",
      "4000 / 4153\n",
      "Finish mouse2_slice139\n",
      "Have samples: ['mouse2_slice151']\n",
      "There are totally 5003 cells in this dataset\n",
      "500 / 5003\n",
      "1000 / 5003\n",
      "1500 / 5003\n",
      "2000 / 5003\n",
      "2500 / 5003\n",
      "3000 / 5003\n",
      "3500 / 5003\n",
      "4000 / 5003\n",
      "4500 / 5003\n",
      "5000 / 5003\n",
      "Finish mouse2_slice151\n",
      "Have samples: ['mouse2_slice160']\n",
      "There are totally 4471 cells in this dataset\n",
      "500 / 4471\n",
      "1000 / 4471\n",
      "1500 / 4471\n",
      "2000 / 4471\n",
      "2500 / 4471\n",
      "3000 / 4471\n",
      "3500 / 4471\n",
      "4000 / 4471\n",
      "Finish mouse2_slice160\n",
      "Have samples: ['mouse2_slice169']\n",
      "There are totally 5148 cells in this dataset\n",
      "500 / 5148\n",
      "1000 / 5148\n",
      "1500 / 5148\n",
      "2000 / 5148\n",
      "2500 / 5148\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m samples\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice10\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice102\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice112\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice122\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice131\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice153\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice162\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice170\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice180\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice190\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice200\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice201\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice21\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice212\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice221\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice232\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice241\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice251\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice260\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice271\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice283\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice291\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice301\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice31\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice313\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice326\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice40\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice62\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice71\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice81\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse1_slice91\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice10\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice109\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice119\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice129\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice139\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice151\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice160\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice169\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice189\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice201\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice209\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice219\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice229\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice249\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice261\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice270\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice280\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice289\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice300\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice309\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice31\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice319\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice40\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice61\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice70\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice79\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice90\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse2_slice99\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m samplei \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mevaluate_Brain_MERFISH\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamplei\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mevaluate_Brain_MERFISH\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     43\u001b[0m results\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (stepi, x) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(my_dataloader, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     46\u001b[0m         x \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     48\u001b[0m         cell_type_name\u001b[38;5;241m=\u001b[39m[cell_types_dict[\u001b[38;5;28mint\u001b[39m(i\u001b[38;5;241m.\u001b[39mcpu())] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_types\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n",
      "File \u001b[0;32m/gpfs/gibbs/project/wang_zuoheng/xx244/conda_envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/gpfs/gibbs/project/wang_zuoheng/xx244/conda_envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/gpfs/gibbs/project/wang_zuoheng/xx244/conda_envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/gpfs/gibbs/project/wang_zuoheng/xx244/conda_envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/gpfs/gibbs/project/wang_zuoheng/xx244/GITIII/Mouse_brain_evaluate/evaluate/dataloader.py:169\u001b[0m, in \u001b[0;36mMouse_brain_evaluate_dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    166\u001b[0m centerx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenterx[sample_id][indices]\n\u001b[1;32m    167\u001b[0m centery \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentery[sample_id][indices]\n\u001b[0;32m--> 169\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexps\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    170\u001b[0m type_exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_exp[sample_id][indices]\n\u001b[1;32m    171\u001b[0m y \u001b[38;5;241m=\u001b[39m exp[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples=['mouse1_slice1', 'mouse1_slice10', 'mouse1_slice102', 'mouse1_slice112', 'mouse1_slice122', 'mouse1_slice131', 'mouse1_slice153', 'mouse1_slice162', 'mouse1_slice170', 'mouse1_slice180', 'mouse1_slice190', 'mouse1_slice200', 'mouse1_slice201', 'mouse1_slice21', 'mouse1_slice212', 'mouse1_slice221', 'mouse1_slice232', 'mouse1_slice241', 'mouse1_slice251', 'mouse1_slice260', 'mouse1_slice271', 'mouse1_slice283', 'mouse1_slice291', 'mouse1_slice301', 'mouse1_slice31', 'mouse1_slice313', 'mouse1_slice326', 'mouse1_slice40', 'mouse1_slice50', 'mouse1_slice62', 'mouse1_slice71', 'mouse1_slice81', 'mouse1_slice91', 'mouse2_slice1', 'mouse2_slice10', 'mouse2_slice109', 'mouse2_slice119', 'mouse2_slice129', 'mouse2_slice139', 'mouse2_slice151', 'mouse2_slice160', 'mouse2_slice169', 'mouse2_slice189', 'mouse2_slice20', 'mouse2_slice201', 'mouse2_slice209', 'mouse2_slice219', 'mouse2_slice229', 'mouse2_slice249', 'mouse2_slice261', 'mouse2_slice270', 'mouse2_slice280', 'mouse2_slice289', 'mouse2_slice300', 'mouse2_slice309', 'mouse2_slice31', 'mouse2_slice319', 'mouse2_slice40', 'mouse2_slice50', 'mouse2_slice61', 'mouse2_slice70', 'mouse2_slice79', 'mouse2_slice90', 'mouse2_slice99']\n",
    "for samplei in samples:\n",
    "    evaluate_Brain_MERFISH(samplei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696854a-c7e4-4ad4-812d-008b84640107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
