{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5114e8f5-9d37-421c-8952-fc6e946d48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from dataloader import NSCLC_evaluate_dataset\n",
    "from model import GITIII,Loss_function\n",
    "from calculate_PCC import Calculate_PCC\n",
    "\n",
    "to_save_dir=\"../edges/\"\n",
    "data_dir = \"../../data/NSCLC/processed1/\"\n",
    "\n",
    "ligands_info = torch.load(\"/\".join(data_dir.split(\"/\")[:-2]) + \"/ligands.pth\")\n",
    "genes = torch.load(\"/\".join(data_dir.split(\"/\")[:-2]) + \"/genes.pth\")\n",
    "\n",
    "my_model = GITIII(genes, ligands_info, node_dim=256, edge_dim=128, num_heads=2, n_layers=1, node_dim_small=16,att_dim=8)\n",
    "my_model = my_model.cuda()\n",
    "loss_func = Loss_function(genes, ligands_info).cuda()\n",
    "evaluator=Calculate_PCC(genes,ligands_info)\n",
    "my_model.load_state_dict(torch.load(\"GRIT_best.pth\"))\n",
    "cell_types_dict = {}\n",
    "cnt = 0\n",
    "for cell_typei in ['B-cell', 'NK', 'T CD4 memory', 'T CD4 naive', 'T CD8 memory', 'T CD8 naive', 'Treg', 'endothelial', 'epithelial', 'fibroblast', 'mDC', 'macrophage', 'mast', 'monocyte', 'neutrophil', 'pDC', 'plasmablast', 'tumor 12', 'tumor 13', 'tumor 5', 'tumor 6', 'tumor 9']:\n",
    "    cell_types_dict[cnt] = cell_typei\n",
    "    cnt += 1\n",
    "\n",
    "def evaluate_NSCLC(sample):\n",
    "    my_dataset = NSCLC_evaluate_dataset(processed_dir=data_dir,sample=sample)\n",
    "    my_dataloader = DataLoader(my_dataset, batch_size=1, num_workers=0, shuffle=False)\n",
    "\n",
    "    length = len(my_dataloader)\n",
    "\n",
    "    my_model.eval()\n",
    "\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for (stepi, x) in enumerate(my_dataloader, start=1):\n",
    "            x = {k: v.cuda() for k, v in x.items()}\n",
    "\n",
    "            cell_type_name = [cell_types_dict[int(i.cpu())] for i in x[\"cell_types\"].squeeze(dim=0)]\n",
    "\n",
    "            y_pred = my_model(x)\n",
    "            y = x[\"y\"]\n",
    "            lossi1, lossi2 = loss_func(y_pred, y)\n",
    "            lossi1 = lossi1.cpu().detach()\n",
    "            lossi2 = lossi2.cpu().detach()\n",
    "\n",
    "            attention_score = y_pred[1][0].cpu().detach()\n",
    "            attention_score = attention_score.squeeze(dim=0)\n",
    "            attention_score = attention_score.permute(1, 2, 0)[0, :, :]\n",
    "            # print(torch.topk(attention_score[0, :], k=30, dim=-1))\n",
    "\n",
    "            edges = y_pred[1][1].cpu().detach()\n",
    "            edges = edges.squeeze(dim=0).permute(1, 2, 0)[0, :, :]\n",
    "\n",
    "            position_x = x[\"position_x\"].cpu().detach().squeeze(dim=0)\n",
    "            position_y = x[\"position_y\"].cpu().detach().squeeze(dim=0)\n",
    "\n",
    "            to_save_dict = {\n",
    "                \"edges\": edges,\n",
    "                \"attention_score\": attention_score,\n",
    "                \"position_x\": position_x,\n",
    "                \"position_y\": position_y,\n",
    "                \"cell_type_name\": cell_type_name,\n",
    "                \"loss_all\": lossi1,\n",
    "                \"loss_no_interact\": lossi2,\n",
    "                \"y_pred\": y_pred[0].cpu().detach().squeeze(dim=0),\n",
    "                \"y\": y.cpu().detach().squeeze(dim=0)\n",
    "            }\n",
    "            results.append(to_save_dict)\n",
    "\n",
    "            if stepi % 2000 == 0:\n",
    "                print(stepi, \"/\", length)\n",
    "    concatenated_results = {}\n",
    "    for keyi in results[0].keys():\n",
    "        if keyi not in [\"cell_type_name\"]:\n",
    "            concatenated_results[keyi] = torch.stack([results[j][keyi] for j in range(len(results))], dim=0)\n",
    "        else:\n",
    "            concatenated_results[keyi] = [results[j][keyi] for j in range(len(results))]\n",
    "    torch.save(concatenated_results, to_save_dir + \"edges_\" + sample + \".pth\")\n",
    "\n",
    "    print(\"Finish\", sample)\n",
    "    return concatenated_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bccac-ff3c-4d8e-805a-067aa7ca5ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have samples: ['Lung13']\n",
      "There are totally 77465 cells in this dataset\n",
      "2000 / 77465\n",
      "4000 / 77465\n",
      "6000 / 77465\n",
      "8000 / 77465\n"
     ]
    }
   ],
   "source": [
    "samples=['Lung6', 'Lung13', 'Lung5_Rep1', 'Lung5_Rep3', 'Lung5_Rep2', 'Lung9_Rep1', 'Lung9_Rep2', 'Lung12']\n",
    "for samplei in samples:\n",
    "    evaluate_NSCLC(samplei)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eab439-8e21-4367-8592-26ced4637c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
