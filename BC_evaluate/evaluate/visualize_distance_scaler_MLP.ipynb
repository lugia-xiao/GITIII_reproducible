{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda96122-b557-4f84-9db6-d01e392eeed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from model import GITIII,Loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce79f036-1d3f-472d-99d5-f78d15ed8cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../../data/BC/processed1/\"\n",
    "\n",
    "ligands_info = torch.load(\"/\".join(data_dir.split(\"/\")[:-2]) + \"/ligands.pth\")\n",
    "genes = torch.load(\"/\".join(data_dir.split(\"/\")[:-2]) + \"/genes.pth\")\n",
    "\n",
    "my_model = GITIII(genes, ligands_info, node_dim=256, edge_dim=48, num_heads=2, n_layers=1, node_dim_small=16,att_dim=8)\n",
    "\n",
    "my_model.load_state_dict(torch.load(\"GRIT_best.pth\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c6c046-f4db-42d4-ba45-8af121708bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GITIII(\n",
      "  (embeddings): Embedding(\n",
      "    (cell_encoder1): FFN(\n",
      "      (linear1): Linear(in_features=321, out_features=1024, bias=True)\n",
      "      (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (cell_encoder2): Embedding(29, 256)\n",
      "    (distance_scaler): Sequential(\n",
      "      (0): FFN(\n",
      "        (linear1): Linear(in_features=5, out_features=192, bias=True)\n",
      "        (linear2): Linear(in_features=192, out_features=66, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "      )\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (distance_encoder): FFN(\n",
      "      (linear1): Linear(in_features=5, out_features=192, bias=True)\n",
      "      (linear2): Linear(in_features=192, out_features=66, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (distance_embedding): Sequential(\n",
      "      (0): FFN(\n",
      "        (linear1): Linear(in_features=5, out_features=192, bias=True)\n",
      "        (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "      )\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (ligands_encoder): Linear(in_features=66, out_features=48, bias=True)\n",
      "    (edge_encoder): Linear(in_features=114, out_features=48, bias=False)\n",
      "  )\n",
      "  (encoders): ModuleList()\n",
      "  (last_layer): GRIT_encoder_last_layer(\n",
      "    (W_Q): Linear(in_features=256, out_features=768, bias=True)\n",
      "    (W_K): Linear(in_features=256, out_features=768, bias=True)\n",
      "    (W_Ew): Linear(in_features=48, out_features=48, bias=False)\n",
      "    (W_Eb): Linear(in_features=48, out_features=48, bias=False)\n",
      "    (W_En): Linear(in_features=48, out_features=256, bias=True)\n",
      "    (W_A): Linear(in_features=48, out_features=321, bias=False)\n",
      "    (node_transform): Linear(in_features=256, out_features=321, bias=True)\n",
      "    (edge_transform): Linear(in_features=48, out_features=321, bias=True)\n",
      "    (head): FFN(\n",
      "      (linear1): Linear(in_features=642, out_features=1284, bias=True)\n",
      "      (linear2): Linear(in_features=1284, out_features=321, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (head2): Sequential(\n",
      "      (0): LayerNorm((321,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): FFN(\n",
      "        (linear1): Linear(in_features=321, out_features=1284, bias=True)\n",
      "        (linear2): Linear(in_features=1284, out_features=321, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a0a1dc-dd96-46da-bd96-f0d2e2f2597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Distance_scaler(nn.Module):\n",
    "    def __init__(self, main_model):\n",
    "        super(Distance_scaler, self).__init__()\n",
    "        self.mlp = main_model.embeddings.distance_scaler\n",
    "    \n",
    "    def forward(self, distances):\n",
    "        distance_matrix = torch.stack([1 / (distances + 1), 1 / (torch.sqrt(distances) + 1),\n",
    "                                   1 / (1 + torch.square(distances)), torch.exp(-distances),\n",
    "                                   torch.exp(-torch.square(distances))], dim=-1)\n",
    "        return self.mlp(distance_matrix)\n",
    "\n",
    "my_ds=Distance_scaler(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aab936c-e6ee-47e1-8c78-eee0750e9af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15]) tensor([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181, 201, 221, 241, 261,\n",
      "        281])\n",
      "torch.Size([15, 66]) tensor([[0.6028, 0.2822, 0.2984, 0.3703, 0.5236, 0.5095, 0.4380, 0.4973, 0.6112,\n",
      "         0.4823, 0.6475, 0.3913, 0.4575, 0.3851, 0.5054, 0.4240, 0.3584, 0.5443,\n",
      "         0.4523, 0.2824, 0.3609, 0.4542, 0.5520, 0.6506, 0.3285, 0.4995, 0.5083,\n",
      "         0.3667, 0.1764, 0.4253, 0.8071, 0.5259, 0.4599, 0.7754, 0.3454, 0.6425,\n",
      "         0.3797, 0.6773, 0.4365, 0.4481, 0.6756, 0.5087, 0.3567, 0.6617, 0.6293,\n",
      "         0.6712, 0.4318, 0.5719, 0.4166, 0.4014, 0.6257, 0.4538, 0.4466, 0.3350,\n",
      "         0.4458, 0.5496, 0.4942, 0.6231, 0.6599, 0.6542, 0.5546, 0.4802, 0.5605,\n",
      "         0.4468, 0.4359, 0.4640],\n",
      "        [0.6159, 0.2800, 0.3929, 0.4092, 0.4630, 0.5082, 0.4365, 0.4778, 0.6047,\n",
      "         0.4830, 0.6929, 0.4353, 0.4476, 0.3948, 0.5077, 0.3812, 0.3730, 0.5459,\n",
      "         0.5051, 0.3321, 0.4101, 0.5161, 0.5803, 0.6726, 0.4100, 0.4644, 0.5140,\n",
      "         0.4295, 0.1866, 0.5080, 0.8033, 0.4801, 0.5082, 0.7492, 0.3634, 0.6430,\n",
      "         0.4656, 0.6976, 0.3961, 0.5096, 0.6941, 0.4975, 0.3925, 0.6256, 0.6202,\n",
      "         0.7063, 0.3886, 0.5917, 0.4223, 0.4303, 0.5849, 0.4632, 0.5044, 0.3630,\n",
      "         0.4694, 0.5379, 0.5120, 0.6240, 0.6054, 0.6615, 0.5661, 0.5198, 0.4964,\n",
      "         0.4367, 0.4362, 0.4766],\n",
      "        [0.6152, 0.2786, 0.4009, 0.4120, 0.4587, 0.5084, 0.4379, 0.4756, 0.6038,\n",
      "         0.4846, 0.6945, 0.4394, 0.4466, 0.3954, 0.5080, 0.3785, 0.3726, 0.5463,\n",
      "         0.5079, 0.3373, 0.4144, 0.5211, 0.5810, 0.6729, 0.4153, 0.4622, 0.5108,\n",
      "         0.4337, 0.1879, 0.5110, 0.8011, 0.4791, 0.5119, 0.7471, 0.3665, 0.6403,\n",
      "         0.4704, 0.6978, 0.3946, 0.5131, 0.6951, 0.4959, 0.3971, 0.6242, 0.6187,\n",
      "         0.7059, 0.3857, 0.5938, 0.4224, 0.4332, 0.5806, 0.4650, 0.5072, 0.3653,\n",
      "         0.4722, 0.5365, 0.5138, 0.6217, 0.6003, 0.6619, 0.5660, 0.5218, 0.4925,\n",
      "         0.4361, 0.4365, 0.4790],\n",
      "        [0.6148, 0.2780, 0.4045, 0.4133, 0.4568, 0.5084, 0.4386, 0.4746, 0.6034,\n",
      "         0.4855, 0.6952, 0.4412, 0.4461, 0.3956, 0.5082, 0.3774, 0.3724, 0.5465,\n",
      "         0.5091, 0.3397, 0.4165, 0.5234, 0.5813, 0.6729, 0.4179, 0.4612, 0.5093,\n",
      "         0.4357, 0.1886, 0.5122, 0.8001, 0.4787, 0.5135, 0.7461, 0.3680, 0.6390,\n",
      "         0.4725, 0.6979, 0.3940, 0.5146, 0.6955, 0.4951, 0.3993, 0.6235, 0.6180,\n",
      "         0.7057, 0.3845, 0.5948, 0.4224, 0.4345, 0.5786, 0.4658, 0.5083, 0.3663,\n",
      "         0.4734, 0.5359, 0.5145, 0.6206, 0.5978, 0.6621, 0.5660, 0.5227, 0.4907,\n",
      "         0.4359, 0.4366, 0.4802],\n",
      "        [0.6146, 0.2776, 0.4068, 0.4141, 0.4557, 0.5084, 0.4390, 0.4740, 0.6031,\n",
      "         0.4860, 0.6956, 0.4424, 0.4458, 0.3957, 0.5083, 0.3767, 0.3723, 0.5465,\n",
      "         0.5098, 0.3412, 0.4178, 0.5248, 0.5815, 0.6730, 0.4194, 0.4607, 0.5084,\n",
      "         0.4369, 0.1890, 0.5129, 0.7995, 0.4785, 0.5145, 0.7455, 0.3690, 0.6381,\n",
      "         0.4738, 0.6979, 0.3937, 0.5155, 0.6958, 0.4947, 0.4006, 0.6231, 0.6175,\n",
      "         0.7055, 0.3838, 0.5953, 0.4224, 0.4353, 0.5773, 0.4664, 0.5089, 0.3670,\n",
      "         0.4742, 0.5355, 0.5150, 0.6199, 0.5963, 0.6622, 0.5659, 0.5232, 0.4896,\n",
      "         0.4358, 0.4366, 0.4809],\n",
      "        [0.6144, 0.2773, 0.4083, 0.4146, 0.4549, 0.5084, 0.4392, 0.4736, 0.6029,\n",
      "         0.4863, 0.6959, 0.4432, 0.4456, 0.3958, 0.5084, 0.3762, 0.3722, 0.5466,\n",
      "         0.5103, 0.3422, 0.4187, 0.5258, 0.5816, 0.6730, 0.4205, 0.4603, 0.5078,\n",
      "         0.4377, 0.1893, 0.5134, 0.7990, 0.4783, 0.5152, 0.7451, 0.3696, 0.6375,\n",
      "         0.4746, 0.6978, 0.3935, 0.5161, 0.6960, 0.4943, 0.4015, 0.6228, 0.6171,\n",
      "         0.7053, 0.3833, 0.5957, 0.4224, 0.4358, 0.5764, 0.4667, 0.5094, 0.3674,\n",
      "         0.4747, 0.5352, 0.5153, 0.6195, 0.5953, 0.6623, 0.5659, 0.5236, 0.4889,\n",
      "         0.4357, 0.4367, 0.4814],\n",
      "        [0.6142, 0.2771, 0.4094, 0.4150, 0.4544, 0.5085, 0.4394, 0.4733, 0.6028,\n",
      "         0.4866, 0.6961, 0.4437, 0.4454, 0.3958, 0.5085, 0.3759, 0.3722, 0.5466,\n",
      "         0.5107, 0.3429, 0.4193, 0.5265, 0.5816, 0.6730, 0.4214, 0.4601, 0.5074,\n",
      "         0.4382, 0.1895, 0.5137, 0.7987, 0.4782, 0.5157, 0.7448, 0.3701, 0.6370,\n",
      "         0.4753, 0.6978, 0.3934, 0.5165, 0.6961, 0.4941, 0.4022, 0.6226, 0.6168,\n",
      "         0.7052, 0.3829, 0.5960, 0.4224, 0.4362, 0.5758, 0.4670, 0.5097, 0.3677,\n",
      "         0.4750, 0.5350, 0.5155, 0.6191, 0.5945, 0.6623, 0.5659, 0.5239, 0.4883,\n",
      "         0.4356, 0.4367, 0.4818],\n",
      "        [0.6141, 0.2770, 0.4103, 0.4154, 0.4539, 0.5085, 0.4396, 0.4731, 0.6027,\n",
      "         0.4869, 0.6962, 0.4442, 0.4453, 0.3958, 0.5086, 0.3756, 0.3721, 0.5466,\n",
      "         0.5110, 0.3435, 0.4199, 0.5270, 0.5817, 0.6730, 0.4220, 0.4599, 0.5070,\n",
      "         0.4387, 0.1897, 0.5140, 0.7984, 0.4782, 0.5161, 0.7446, 0.3705, 0.6367,\n",
      "         0.4758, 0.6978, 0.3933, 0.5169, 0.6962, 0.4939, 0.4028, 0.6224, 0.6166,\n",
      "         0.7051, 0.3827, 0.5963, 0.4224, 0.4365, 0.5753, 0.4672, 0.5099, 0.3680,\n",
      "         0.4753, 0.5349, 0.5157, 0.6188, 0.5938, 0.6624, 0.5659, 0.5241, 0.4879,\n",
      "         0.4355, 0.4367, 0.4822],\n",
      "        [0.6140, 0.2768, 0.4110, 0.4156, 0.4536, 0.5085, 0.4397, 0.4729, 0.6026,\n",
      "         0.4870, 0.6963, 0.4446, 0.4452, 0.3959, 0.5086, 0.3754, 0.3721, 0.5467,\n",
      "         0.5112, 0.3440, 0.4203, 0.5275, 0.5817, 0.6730, 0.4225, 0.4597, 0.5067,\n",
      "         0.4391, 0.1898, 0.5142, 0.7982, 0.4781, 0.5165, 0.7444, 0.3708, 0.6364,\n",
      "         0.4762, 0.6978, 0.3932, 0.5171, 0.6963, 0.4937, 0.4032, 0.6223, 0.6165,\n",
      "         0.7050, 0.3824, 0.5965, 0.4224, 0.4368, 0.5748, 0.4674, 0.5101, 0.3682,\n",
      "         0.4756, 0.5348, 0.5159, 0.6186, 0.5933, 0.6624, 0.5659, 0.5243, 0.4875,\n",
      "         0.4355, 0.4368, 0.4824],\n",
      "        [0.6139, 0.2767, 0.4116, 0.4158, 0.4533, 0.5085, 0.4398, 0.4727, 0.6025,\n",
      "         0.4872, 0.6964, 0.4449, 0.4451, 0.3959, 0.5087, 0.3752, 0.3721, 0.5467,\n",
      "         0.5114, 0.3444, 0.4206, 0.5279, 0.5818, 0.6730, 0.4230, 0.4596, 0.5065,\n",
      "         0.4394, 0.1899, 0.5144, 0.7980, 0.4781, 0.5167, 0.7442, 0.3711, 0.6361,\n",
      "         0.4765, 0.6978, 0.3931, 0.5174, 0.6963, 0.4936, 0.4036, 0.6222, 0.6163,\n",
      "         0.7050, 0.3823, 0.5966, 0.4224, 0.4370, 0.5745, 0.4675, 0.5103, 0.3684,\n",
      "         0.4758, 0.5347, 0.5160, 0.6184, 0.5929, 0.6625, 0.5659, 0.5244, 0.4872,\n",
      "         0.4354, 0.4368, 0.4826],\n",
      "        [0.6138, 0.2766, 0.4121, 0.4160, 0.4530, 0.5085, 0.4399, 0.4726, 0.6025,\n",
      "         0.4873, 0.6965, 0.4451, 0.4450, 0.3959, 0.5087, 0.3750, 0.3720, 0.5467,\n",
      "         0.5116, 0.3447, 0.4210, 0.5282, 0.5818, 0.6730, 0.4233, 0.4594, 0.5063,\n",
      "         0.4397, 0.1900, 0.5145, 0.7978, 0.4780, 0.5170, 0.7441, 0.3713, 0.6359,\n",
      "         0.4768, 0.6978, 0.3931, 0.5175, 0.6964, 0.4934, 0.4039, 0.6221, 0.6162,\n",
      "         0.7049, 0.3821, 0.5968, 0.4223, 0.4371, 0.5742, 0.4676, 0.5104, 0.3685,\n",
      "         0.4759, 0.5346, 0.5161, 0.6183, 0.5925, 0.6625, 0.5659, 0.5246, 0.4870,\n",
      "         0.4354, 0.4368, 0.4828],\n",
      "        [0.6138, 0.2765, 0.4126, 0.4162, 0.4528, 0.5085, 0.4400, 0.4724, 0.6024,\n",
      "         0.4874, 0.6966, 0.4453, 0.4450, 0.3959, 0.5087, 0.3749, 0.3720, 0.5467,\n",
      "         0.5117, 0.3450, 0.4212, 0.5284, 0.5818, 0.6730, 0.4237, 0.4593, 0.5061,\n",
      "         0.4399, 0.1901, 0.5147, 0.7977, 0.4780, 0.5172, 0.7439, 0.3715, 0.6357,\n",
      "         0.4770, 0.6978, 0.3930, 0.5177, 0.6964, 0.4933, 0.4042, 0.6220, 0.6161,\n",
      "         0.7049, 0.3820, 0.5969, 0.4223, 0.4373, 0.5739, 0.4677, 0.5105, 0.3687,\n",
      "         0.4761, 0.5345, 0.5162, 0.6181, 0.5922, 0.6625, 0.5659, 0.5247, 0.4868,\n",
      "         0.4354, 0.4368, 0.4830],\n",
      "        [0.6137, 0.2765, 0.4130, 0.4163, 0.4526, 0.5085, 0.4400, 0.4723, 0.6024,\n",
      "         0.4875, 0.6966, 0.4455, 0.4449, 0.3959, 0.5088, 0.3748, 0.3720, 0.5467,\n",
      "         0.5118, 0.3453, 0.4214, 0.5287, 0.5819, 0.6730, 0.4240, 0.4593, 0.5060,\n",
      "         0.4401, 0.1902, 0.5148, 0.7976, 0.4780, 0.5173, 0.7438, 0.3717, 0.6355,\n",
      "         0.4772, 0.6978, 0.3930, 0.5178, 0.6965, 0.4932, 0.4044, 0.6219, 0.6160,\n",
      "         0.7048, 0.3819, 0.5970, 0.4223, 0.4374, 0.5737, 0.4678, 0.5106, 0.3688,\n",
      "         0.4762, 0.5345, 0.5163, 0.6180, 0.5919, 0.6625, 0.5658, 0.5247, 0.4866,\n",
      "         0.4354, 0.4368, 0.4831],\n",
      "        [0.6137, 0.2764, 0.4133, 0.4164, 0.4525, 0.5085, 0.4401, 0.4722, 0.6023,\n",
      "         0.4876, 0.6967, 0.4457, 0.4449, 0.3959, 0.5088, 0.3747, 0.3720, 0.5467,\n",
      "         0.5119, 0.3455, 0.4216, 0.5289, 0.5819, 0.6730, 0.4242, 0.4592, 0.5058,\n",
      "         0.4403, 0.1902, 0.5149, 0.7975, 0.4780, 0.5175, 0.7438, 0.3719, 0.6354,\n",
      "         0.4774, 0.6977, 0.3929, 0.5180, 0.6965, 0.4932, 0.4047, 0.6218, 0.6159,\n",
      "         0.7048, 0.3818, 0.5971, 0.4223, 0.4375, 0.5735, 0.4679, 0.5107, 0.3689,\n",
      "         0.4763, 0.5344, 0.5163, 0.6179, 0.5917, 0.6626, 0.5658, 0.5248, 0.4864,\n",
      "         0.4353, 0.4368, 0.4833],\n",
      "        [0.6136, 0.2764, 0.4136, 0.4165, 0.4523, 0.5085, 0.4401, 0.4722, 0.6023,\n",
      "         0.4877, 0.6967, 0.4459, 0.4448, 0.3959, 0.5088, 0.3746, 0.3720, 0.5467,\n",
      "         0.5120, 0.3457, 0.4218, 0.5291, 0.5819, 0.6730, 0.4244, 0.4591, 0.5057,\n",
      "         0.4404, 0.1903, 0.5149, 0.7974, 0.4780, 0.5176, 0.7437, 0.3720, 0.6353,\n",
      "         0.4776, 0.6977, 0.3929, 0.5181, 0.6965, 0.4931, 0.4048, 0.6218, 0.6158,\n",
      "         0.7048, 0.3817, 0.5971, 0.4223, 0.4376, 0.5733, 0.4680, 0.5108, 0.3690,\n",
      "         0.4764, 0.5344, 0.5164, 0.6178, 0.5915, 0.6626, 0.5658, 0.5249, 0.4863,\n",
      "         0.4353, 0.4368, 0.4834]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(1,300,20)\n",
    "print(x.shape,x)\n",
    "scaler=my_ds(x)\n",
    "print(scaler.shape,scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2614a24-ee28-4f2f-8558-4af52ffcb758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
